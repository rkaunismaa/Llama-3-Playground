{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wednesday, April 24, 2024\n",
    "\n",
    "mamba activate llama3\n",
    "\n",
    "[pip trl](https://pypi.org/project/trl/)\n",
    "\n",
    "This is a basic example of how to use the SFTTrainer from the library. The SFTTrainer is a light wrapper around the transformers Trainer to easily fine-tune language models or adapters on a custom dataset.\n",
    "\n",
    "Nice! This all runs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only target the 4090 ...\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yup, still getting errors complaining about the 4090 ... \n",
    "#   Using RTX 4000 series doesn't support faster communication broadband via P2P or IB. \n",
    "#   Please set `NCCL_P2P_DISABLE=\"1\"` and `NCCL_IB_DISABLE=\"1\" or use `accelerate launch` which will do this automatically.\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"NCCL_P2P_DISABLE\"]=\"1\"\n",
    "os.environ[\"NCCL_IB_DISABLE\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset\n",
    "dataset = load_dataset(\"imdb\", split=\"train\")\n",
    "\n",
    "# 1m 15.7s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rob/miniforge3/envs/llama3/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:166: UserWarning: You passed a model_id to the SFTTrainer. This will automatically create an `AutoModelForCausalLM` or a `PeftModel` (if you passed a `peft_config`) for you.\n",
      "  warnings.warn(\n",
      "/home/rob/miniforge3/envs/llama3/lib/python3.11/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# get trainer\n",
    "trainer = SFTTrainer(\n",
    "    \"facebook/opt-350m\",\n",
    "    train_dataset=dataset,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrobkayinto\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/rob/Data/Documents/Github/rkaunismaa/Llama-3-Playground/trl-tester/wandb/run-20240424_104339-vzne7alf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/robkayinto/huggingface/runs/vzne7alf/workspace' target=\"_blank\">solar-wildflower-50</a></strong> to <a href='https://wandb.ai/robkayinto/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/robkayinto/huggingface' target=\"_blank\">https://wandb.ai/robkayinto/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/robkayinto/huggingface/runs/vzne7alf/workspace' target=\"_blank\">https://wandb.ai/robkayinto/huggingface/runs/vzne7alf/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19abfbed90e48359fd5238eb9b329c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.5513, 'grad_norm': 5.665127754211426, 'learning_rate': 4.7333333333333336e-05, 'epoch': 0.16}\n",
      "{'loss': 3.517, 'grad_norm': 4.847421169281006, 'learning_rate': 4.466666666666667e-05, 'epoch': 0.32}\n",
      "{'loss': 3.4984, 'grad_norm': 5.284757614135742, 'learning_rate': 4.2e-05, 'epoch': 0.48}\n",
      "{'loss': 3.4731, 'grad_norm': 4.712557315826416, 'learning_rate': 3.933333333333333e-05, 'epoch': 0.64}\n",
      "{'loss': 3.4531, 'grad_norm': 4.860318183898926, 'learning_rate': 3.6666666666666666e-05, 'epoch': 0.8}\n",
      "{'loss': 3.4202, 'grad_norm': 5.849560260772705, 'learning_rate': 3.4000000000000007e-05, 'epoch': 0.96}\n",
      "{'loss': 3.1707, 'grad_norm': 6.171912670135498, 'learning_rate': 3.1333333333333334e-05, 'epoch': 1.12}\n",
      "{'loss': 3.1128, 'grad_norm': 4.704696178436279, 'learning_rate': 2.8666666666666668e-05, 'epoch': 1.28}\n",
      "{'loss': 3.1158, 'grad_norm': 4.590517520904541, 'learning_rate': 2.6000000000000002e-05, 'epoch': 1.44}\n",
      "{'loss': 3.1098, 'grad_norm': 5.3792901039123535, 'learning_rate': 2.3333333333333336e-05, 'epoch': 1.6}\n",
      "{'loss': 3.1017, 'grad_norm': 4.773280620574951, 'learning_rate': 2.0666666666666666e-05, 'epoch': 1.76}\n",
      "{'loss': 3.1021, 'grad_norm': 5.209169864654541, 'learning_rate': 1.8e-05, 'epoch': 1.92}\n",
      "{'loss': 2.9557, 'grad_norm': 4.844482898712158, 'learning_rate': 1.5333333333333334e-05, 'epoch': 2.08}\n",
      "{'loss': 2.8154, 'grad_norm': 6.0888848304748535, 'learning_rate': 1.2666666666666668e-05, 'epoch': 2.24}\n",
      "{'loss': 2.8268, 'grad_norm': 4.182015895843506, 'learning_rate': 1e-05, 'epoch': 2.4}\n",
      "{'loss': 2.817, 'grad_norm': 5.131466865539551, 'learning_rate': 7.333333333333334e-06, 'epoch': 2.56}\n",
      "{'loss': 2.8148, 'grad_norm': 4.6306610107421875, 'learning_rate': 4.666666666666667e-06, 'epoch': 2.72}\n",
      "{'loss': 2.8169, 'grad_norm': 5.243734836578369, 'learning_rate': 2.0000000000000003e-06, 'epoch': 2.88}\n",
      "{'train_runtime': 3077.2554, 'train_samples_per_second': 24.372, 'train_steps_per_second': 3.047, 'train_loss': 3.134981015625, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9375, training_loss=3.134981015625, metrics={'train_runtime': 3077.2554, 'train_samples_per_second': 24.372, 'train_steps_per_second': 3.047, 'train_loss': 3.134981015625, 'epoch': 3.0})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "trainer.train()\n",
    "\n",
    "# 51m 17.2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 24 11:35:15 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.29.06              Driver Version: 545.29.06    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1050        Off | 00000000:01:00.0  On |                  N/A |\n",
      "| 39%   59C    P0              N/A /  70W |    489MiB /  2048MiB |      8%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 4090        Off | 00000000:02:00.0 Off |                  Off |\n",
      "| 56%   64C    P8              51W / 450W |  18526MiB / 24564MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      2217      G   /usr/lib/xorg/Xorg                          241MiB |\n",
      "|    0   N/A  N/A      2483      G   /usr/bin/gnome-shell                         49MiB |\n",
      "|    0   N/A  N/A      5632      G   ...,262144 --variations-seed-version=1       83MiB |\n",
      "|    0   N/A  N/A    167807      G   ...erProcess --variations-seed-version      109MiB |\n",
      "|    1   N/A  N/A      2217      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    1   N/A  N/A    168574      C   ...b/miniforge3/envs/llama3/bin/python    18506MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
